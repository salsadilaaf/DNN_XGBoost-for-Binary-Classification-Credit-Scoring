{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EYf7pmZjGtA"
      },
      "source": [
        "#**Import dan Instal Library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i_z_7-0svTK",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib-venn\n",
        "!pip install jcopml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "an554dvOrTcO"
      },
      "outputs": [],
      "source": [
        "# Import library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt # Untuk membuat plot\n",
        "import seaborn as sns\n",
        "from jcopml.plot import plot_missing_value # Untuk plot missing value\n",
        "from sklearn.model_selection import train_test_split # Untuk splitting dataset\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from collections import Counter\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "id": "pH73ad1mWrIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2vvIDHArRLH"
      },
      "source": [
        "#**Import Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjTlCYMeRMPn"
      },
      "outputs": [],
      "source": [
        "# Data German\n",
        "df = pd.read_csv('/content/drive/MyDrive/Dataset/german.csv')\n",
        "df.rename(columns={'Status':'TARGET'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfxF3JbCROLQ"
      },
      "outputs": [],
      "source": [
        "# Data Japanese\n",
        "df = pd.read_csv('/content/drive/MyDrive/Dataset/japanese baru.csv')\n",
        "df.rename(columns={'A16':'TARGET'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data HMEQ\n",
        "df = pd.read_csv('/content/drive/MyDrive/Dataset/hmeq.csv')\n",
        "df.rename(columns={'BAD':'TARGET'}, inplace=True)"
      ],
      "metadata": {
        "id": "MoUr8rNuIS2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byblEluSsPim"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4kqzuTfQxSG"
      },
      "source": [
        "##**Statistika Deskriptif**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiwVBl1scKDj"
      },
      "outputs": [],
      "source": [
        "## Statistika Descriptif\n",
        "df.info() # Melihat banyak entri, tipe data, dan data yang tidak kosong\n",
        "print(df.nunique()) # Melihat nilai unik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kYSU_ux1udD"
      },
      "outputs": [],
      "source": [
        "df['TARGET']=pd.Categorical(df.TARGET) # Mengubah colom target menjadi tipe kategori\n",
        "df.info()\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v1JSAvpswXb"
      },
      "source": [
        "#**Preprocesing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhxI15FdNHpm"
      },
      "source": [
        "##**Outlier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THwc3oJYSk0m"
      },
      "outputs": [],
      "source": [
        "#Memisahkan kumpulan data menjadi data numerik saja\n",
        "numerical_df = df.select_dtypes(include=[np.number])\n",
        "numerical_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt44bPixNWla"
      },
      "outputs": [],
      "source": [
        "#Cek outlier pada data numerik menggunakan boxplot\n",
        "def num_plot(df, var):\n",
        "    plt.subplot\n",
        "    sns.boxplot(y = df[var])\n",
        "    plt.title(\"Boxplot\")\n",
        "    plt.show()\n",
        "\n",
        "for var in numerical_df:\n",
        "    num_plot(df, var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqN9QtbslU3S"
      },
      "outputs": [],
      "source": [
        "# Fungsi untuk menghilangkan outlier menggunakan metode IQR\n",
        "def remove_outliers(df, column_list):\n",
        "    cleaned_df = df.copy()\n",
        "    for column in column_list:\n",
        "        Q1 = cleaned_df[column].quantile(0.25)\n",
        "        Q3 = cleaned_df[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        # Memfilter outliers\n",
        "        cleaned_df = cleaned_df[(cleaned_df[column] >= lower_bound) & (cleaned_df[column] <= upper_bound)]\n",
        "\n",
        "    return cleaned_df\n",
        "\n",
        "# Aplikasikan fungsi pada data numerik\n",
        "df = remove_outliers(df, numerical_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ES-nIfVxJ_V"
      },
      "outputs": [],
      "source": [
        "## Statistika Descriptif\n",
        "df.info() # Melihat banyak entri, tipe data, dan data yang tidak kosong"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VTlNPsLzNHW"
      },
      "outputs": [],
      "source": [
        "for var in numerical_df:\n",
        "    num_plot(df, var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWDiYxq_slz1"
      },
      "source": [
        "##**Cek Data Imbalance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRP0QMBWPiQg"
      },
      "outputs": [],
      "source": [
        "# Cek imbalance data\n",
        "df[\"TARGET\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSSNiFOsxU0r"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.countplot(df[\"TARGET\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spuEYz-xseJo"
      },
      "source": [
        "##**Cek Missing Value**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv03YpeupBZ7"
      },
      "outputs": [],
      "source": [
        "# Cek missing value\n",
        "missing_values = df.isnull().sum(axis=0)\n",
        "print(missing_values)\n",
        "plot_missing_value(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ70WtDNUtfl"
      },
      "outputs": [],
      "source": [
        "# Create a bar plot of missing values\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.bar(missing_values.index, missing_values.values)\n",
        "plt.title('Missing Value Count')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Penanganan Missing Value, Standarisasi, dan One-Hot Encoding**"
      ],
      "metadata": {
        "id": "TvfpJB5rHi4t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2TWqL8CSBPR"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Preprocessing untuk kolom numerik\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),# Mengisi nilai yang hilang\n",
        "    ('scaler', StandardScaler()) # Standardisasi\n",
        "])\n",
        "# Preprocessing untuk kolom kategorikal\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "# Bundle preprocessing untuk kolom numerik dan kategorikal\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Split Data**"
      ],
      "metadata": {
        "id": "IpX8knx5HuRI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqJwNXsYcr_Z"
      },
      "outputs": [],
      "source": [
        "# Splitting data\n",
        "X = df.drop(columns=\"TARGET\")\n",
        "y = df.TARGET\n",
        "# Split data menjadi training dan testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y,\n",
        "random_state=42)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek nilai missing value sebelum preprocessing\n",
        "print(\"Missing values in training data before preprocessing:\\n\", X_train.isna().sum())\n",
        "print(\"Missing values in testing data before preprocessing:\\n\", X_test.isna().sum())"
      ],
      "metadata": {
        "id": "GXjAQoRjjucS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5LmsoPGFI2L"
      },
      "outputs": [],
      "source": [
        "# Terapkan preprocessing ke data\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek nilai missing value setelah preprocessing (pada array numpy)\n",
        "print(\"Missing values in training data after preprocessing:\", np.isnan(X_train).sum())\n",
        "print(\"Missing values in testing data after preprocessing:\", np.isnan(X_test).sum())"
      ],
      "metadata": {
        "id": "23VBDZqijxSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**SMOTE**"
      ],
      "metadata": {
        "id": "ncBaz3R9HPrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi SMOTE dan resample data training\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train, y_train = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "SG5oXzzHQi5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = pd.value_counts(y_train)\n",
        "print(class_counts)"
      ],
      "metadata": {
        "id": "Oo34XP5VQjkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat bar chart\n",
        "plt.barh(class_counts.index, class_counts.values)\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Class')\n",
        "plt.title('Class Distribution after SMOTE')\n",
        "plt.yticks([0, 1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_5p3yPq7Tb76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**MIXED MODEL**"
      ],
      "metadata": {
        "id": "jNMwSn-2k45A"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biczyfYpTsdp"
      },
      "source": [
        "##**Deep Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xaPuOvJ2J3Y"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def build_dnn_for_feature_extraction(input_shape):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    x = Dense(32, activation='relu')(input_layer)\n",
        "    x = Dense(16, activation='relu')(x)\n",
        "    feature_layer = Dense(8, activation='relu')(x)\n",
        "    output_layer = Dense(1, activation='sigmoid')(feature_layer)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    feature_model = Model(inputs=input_layer, outputs=feature_layer)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "\n",
        "    return model, feature_model\n",
        "\n",
        "# Buat model dan ekstrak fitur tanpa subset\n",
        "model, feature_model = build_dnn_for_feature_extraction((X_train.shape[1],))\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=30)\n",
        "\n",
        "extracted_features_train = feature_model.predict(X_train)\n",
        "extracted_features_test = feature_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYKOErfEV84U"
      },
      "source": [
        "###**Evaluasi dan Hasil**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL9NkVmTWFwV"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPcHOI9CY0rv"
      },
      "outputs": [],
      "source": [
        "y_pred_dnn = y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WOyneurWG7R"
      },
      "outputs": [],
      "source": [
        "print(extracted_features_train[:5])  # Menampilkan 5 baris pertama dari data pelatihan"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Konversi array numpy menjadi DataFrame\n",
        "df_train = pd.DataFrame(extracted_features_train[:5])\n",
        "\n",
        "# Menampilkan DataFrame\n",
        "print(df_train)"
      ],
      "metadata": {
        "id": "V29QTDx_t-D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URzZwKmroRnE"
      },
      "source": [
        "##**Extreme Gradient Boosting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqc2Gabf_rfs"
      },
      "source": [
        "###**Tanpa Imbalanced**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Inisialisasi model XGBoost\n",
        "xgb_model = XGBClassifier(\n",
        "   booster='gbtree',\n",
        "   n_estimators=500,\n",
        "   learning_rate=0.1,\n",
        "   max_depth=6,\n",
        "   subsample=0.8,\n",
        "   colsample_bytree=0.8,\n",
        "   gamma=1,\n",
        "   reg_alpha=0.1,\n",
        "   reg_lambda=1,\n",
        "   objective='binary:logistic'\n",
        ")\n",
        "\n",
        "# Latih model XGBoost dengan fitur yang diekstraksi dan data asli\n",
        "xgb_model.fit(extracted_features_train, y_train)\n",
        "\n",
        "# Memprediksi menggunakan model pada data uji\n",
        "predictions = xgb_model.predict(extracted_features_test)\n",
        "\n",
        "# Evaluasi model\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy on test set:\", accuracy)\n",
        "\n",
        "# Tampilkan laporan klasifikasi\n",
        "print(classification_report(y_test, predictions))\n"
      ],
      "metadata": {
        "id": "r1BimcEs3OwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "# Hitung confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "# Ekstrak nilai TP, TN, FP, FN dari confusion matrix\n",
        "TP = conf_matrix[1, 1]\n",
        "TN = conf_matrix[0, 0]\n",
        "FP = conf_matrix[0, 1]\n",
        "FN = conf_matrix[1, 0]\n",
        "\n",
        "# Hitung metric lainnya\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "roc_auc = roc_auc_score(y_test, predictions)\n",
        "\n",
        "# Cetak hasil\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nTrue Positive (TP):\", TP)\n",
        "print(\"True Negative (TN):\", TN)\n",
        "print(\"False Positive (FP):\", FP)\n",
        "print(\"False Negative (FN):\", FN)\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC:\", roc_auc)"
      ],
      "metadata": {
        "id": "KCgu0BLJg6hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Smote"
      ],
      "metadata": {
        "id": "MmYBtDY62uYv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2pbAAn8_w45"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Ekstrak fitur menggunakan DNN dari seluruh data pelatihan\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(extracted_features_train, y_train)\n",
        "\n",
        "# Inisialisasi model XGBoost\n",
        "xgb_model = XGBClassifier(\n",
        "   n_estimators=100,\n",
        "   learning_rate=0.1,\n",
        "   max_depth=6,\n",
        "   subsample=0.8,\n",
        "   colsample_bytree=0.8,\n",
        "   gamma=1,\n",
        "   reg_alpha=0.1,\n",
        "   reg_lambda=1\n",
        ")\n",
        "\n",
        "# Latih model XGBoost dengan fitur yang diekstraksi dan data yang telah di-resample\n",
        "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Memprediksi menggunakan model pada data uji\n",
        "predictions = xgb_model.predict(extracted_features_test)\n",
        "\n",
        "# Evaluasi model\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy on test set:\", accuracy)\n",
        "\n",
        "# Tampilkan laporan klasifikasi\n",
        "print(classification_report(y_test, predictions))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "# Hitung confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "# Ekstrak nilai TP, TN, FP, FN dari confusion matrix\n",
        "TP = conf_matrix[1, 1]\n",
        "TN = conf_matrix[0, 0]\n",
        "FP = conf_matrix[0, 1]\n",
        "FN = conf_matrix[1, 0]\n",
        "\n",
        "# Hitung metric lainnya\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "roc_auc = roc_auc_score(y_test, predictions)\n",
        "\n",
        "# Cetak hasil\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nTrue Positive (TP):\", TP)\n",
        "print(\"True Negative (TN):\", TN)\n",
        "print(\"False Positive (FP):\", FP)\n",
        "print(\"False Negative (FN):\", FN)\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC:\", roc_auc)"
      ],
      "metadata": {
        "id": "weqQqVOHm2Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Scale Pos Weight"
      ],
      "metadata": {
        "id": "j7Ue7qKS2xUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Menghitung rasio kelas minoritas terhadap kelas mayoritas\n",
        "class_ratio = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
        "\n",
        "# Inisialisasi model XGBoost dengan scale_pos_weight\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    gamma=1,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1,\n",
        "    scale_pos_weight=class_ratio\n",
        ")\n",
        "\n",
        "# Latih model XGBoost dengan fitur yang diekstraksi dan data asli\n",
        "xgb_model.fit(extracted_features_train, y_train)\n",
        "\n",
        "# Memprediksi menggunakan model pada data uji\n",
        "predictions = xgb_model.predict(extracted_features_test)\n",
        "\n",
        "# Evaluasi model\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy on test set:\", accuracy)\n",
        "\n",
        "# Tampilkan laporan klasifikasi\n",
        "print(classification_report(y_test, predictions))\n"
      ],
      "metadata": {
        "id": "tzQQmEmx209e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "# Hitung confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "# Ekstrak nilai TP, TN, FP, FN dari confusion matrix\n",
        "TP = conf_matrix[1, 1]\n",
        "TN = conf_matrix[0, 0]\n",
        "FP = conf_matrix[0, 1]\n",
        "FN = conf_matrix[1, 0]\n",
        "\n",
        "# Hitung metric lainnya\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "roc_auc = roc_auc_score(y_test, predictions)\n",
        "\n",
        "# Cetak hasil\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nTrue Positive (TP):\", TP)\n",
        "print(\"True Negative (TN):\", TN)\n",
        "print(\"False Positive (FP):\", FP)\n",
        "print(\"False Negative (FN):\", FN)\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC:\", roc_auc)"
      ],
      "metadata": {
        "id": "CVebA2zYhD6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**SINGLE MODEL**"
      ],
      "metadata": {
        "id": "c8GF7jx2Gjn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##XGBoost"
      ],
      "metadata": {
        "id": "rml_Th4cuHir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "\n",
        "# Inisialisasi model\n",
        "model_xgb = xgb.XGBClassifier()\n",
        "\n",
        "# Melatih model pada data latih\n",
        "model_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Membuat prediksi menggunakan data uji\n",
        "y_pred_xgb = model_xgb.predict(X_test)\n",
        "\n",
        "# Menghitung confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_xgb)\n",
        "\n",
        "# Mengambil nilai dari confusion matrix\n",
        "TN, FP, FN, TP = conf_matrix.ravel()\n",
        "\n",
        "# Menghitung tipe I dan tipe II error\n",
        "type_i_error = FP\n",
        "type_ii_error = FN\n",
        "\n",
        "# Hitung metric lainnya\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_xgb)\n",
        "\n",
        "# Cetak hasil\n",
        "print(\"XGBoost Model Metrics:\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nTrue Positive (TP):\", TP)\n",
        "print(\"True Negative (TN):\", TN)\n",
        "print(\"False Positive (FP):\", FP)\n",
        "print(\"False Negative (FN):\", FN)\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC:\", roc_auc)"
      ],
      "metadata": {
        "id": "gYKCtUdOuLFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GBM"
      ],
      "metadata": {
        "id": "Y0TdQRrNGqqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Inisialisasi model\n",
        "model_gbm = GradientBoostingClassifier()\n",
        "\n",
        "# Melatih model pada data latih\n",
        "model_gbm.fit(X_train, y_train)\n",
        "\n",
        "# Membuat prediksi menggunakan data uji\n",
        "y_pred_gbm = model_gbm.predict(X_test)\n",
        "\n",
        "# Menghitung confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_gbm)\n",
        "\n",
        "# Mengambil nilai dari confusion matrix\n",
        "TN, FP, FN, TP = conf_matrix.ravel()\n",
        "\n",
        "# Menghitung tipe I dan tipe II error\n",
        "type_i_error = FP\n",
        "type_ii_error = FN\n",
        "# Hitung metric lainnya\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_gbm)\n",
        "\n",
        "# Cetak hasil\n",
        "print(\"Gradient Boosting Machine (GBM) Model Metrics:\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nTrue Positive (TP):\", TP)\n",
        "print(\"True Negative (TN):\", TN)\n",
        "print(\"False Positive (FP):\", FP)\n",
        "print(\"False Negative (FN):\", FN)\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC:\", roc_auc)"
      ],
      "metadata": {
        "id": "4ershJ_grX5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Logistic Regression"
      ],
      "metadata": {
        "id": "IXZRXlyJ30pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Inisialisasi model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Melatih model pada data latih\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Membuat prediksi menggunakan data uji\n",
        "y_pred_lr = model.predict(X_test)\n",
        "\n",
        "# Menghitung confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_lr)\n",
        "\n",
        "# Mengambil nilai dari confusion matrix\n",
        "TN, FP, FN, TP = conf_matrix.ravel()\n",
        "\n",
        "# Menghitung tipe I dan tipe II error\n",
        "type_i_error = FP\n",
        "type_ii_error = FN\n",
        "# Hitung metric lainnya\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_lr)\n",
        "\n",
        "# Cetak hasil\n",
        "print(\"Logistic Regression Model Metrics:\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nTrue Positive (TP):\", TP)\n",
        "print(\"True Negative (TN):\", TN)\n",
        "print(\"False Positive (FP):\", FP)\n",
        "print(\"False Negative (FN):\", FN)\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC:\", roc_auc)"
      ],
      "metadata": {
        "id": "A9b-Q0AHhIuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Decision Tree"
      ],
      "metadata": {
        "id": "sFVUocOB5gx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree, metrics, model_selection, preprocessing\n",
        "from IPython.display import Image, display"
      ],
      "metadata": {
        "id": "2ql6XOGaLbF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the decision tree\n",
        "dtree = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
        "dtree.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "A2Ssif3R5pr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_dt = dtree.predict(X_test)"
      ],
      "metadata": {
        "id": "n87L27NbLAIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghitung confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_dt)\n",
        "\n",
        "# Mengambil nilai dari confusion matrix\n",
        "TN, FP, FN, TP = conf_matrix.ravel()\n",
        "\n",
        "# Menghitung tipe I dan tipe II error\n",
        "type_i_error = FP\n",
        "type_ii_error = FN\n",
        "# Hitung metric lainnya\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_dt)\n",
        "\n",
        "# Cetak hasil\n",
        "print(\"Decision Tree Model Metrics:\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nTrue Positive (TP):\", TP)\n",
        "print(\"True Negative (TN):\", TN)\n",
        "print(\"False Positive (FP):\", FP)\n",
        "print(\"False Negative (FN):\", FN)\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC:\", roc_auc)"
      ],
      "metadata": {
        "id": "poRwJ0bXLGY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random Forest"
      ],
      "metadata": {
        "id": "79l8DOpQ5nZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "6QmepqgeGYVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rf = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "IwiiOznQT2iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghitung confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "# Mengambil nilai dari confusion matrix\n",
        "TN, FP, FN, TP = conf_matrix.ravel()\n",
        "\n",
        "# Menghitung tipe I dan tipe II error\n",
        "type_i_error = FP\n",
        "type_ii_error = FN\n",
        "# Hitung metric lainnya\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_rf)\n",
        "\n",
        "# Cetak hasil\n",
        "print(\"Random Forest Model Metrics:\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nTrue Positive (TP):\", TP)\n",
        "print(\"True Negative (TN):\", TN)\n",
        "print(\"False Positive (FP):\", FP)\n",
        "print(\"False Negative (FN):\", FN)\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC:\", roc_auc)"
      ],
      "metadata": {
        "id": "KwruxDx5UMA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Support Vector Mechine"
      ],
      "metadata": {
        "id": "YL4a4gl7GS1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Inisialisasi model SVM\n",
        "svm_model = SVC()\n",
        "\n",
        "# Melatih model pada data latih\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Membuat prediksi menggunakan data uji\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "# Menghitung confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_svm)\n",
        "\n",
        "# Mengambil nilai dari confusion matrix\n",
        "TN, FP, FN, TP = conf_matrix.ravel()\n",
        "\n",
        "# Menghitung tipe I dan tipe II error\n",
        "type_i_error = FP\n",
        "type_ii_error = FN\n",
        "# Hitung metric lainnya\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_svm)\n",
        "\n",
        "# Cetak hasil\n",
        "print(\"Support Vector Machine Model Metrics:\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nTrue Positive (TP):\", TP)\n",
        "print(\"True Negative (TN):\", TN)\n",
        "print(\"False Positive (FP):\", FP)\n",
        "print(\"False Negative (FN):\", FN)\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC:\", roc_auc)\n"
      ],
      "metadata": {
        "id": "ZCLiBVN0GWbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ADA BOOST"
      ],
      "metadata": {
        "id": "9QmYr13QGZCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Inisialisasi model\n",
        "model_adaboost = AdaBoostClassifier()\n",
        "\n",
        "# Melatih model pada data latih\n",
        "model_adaboost.fit(X_train, y_train)\n",
        "\n",
        "# Membuat prediksi menggunakan data uji\n",
        "y_pred_adaboost = model_adaboost.predict(X_test)\n",
        "\n",
        "# Menghitung confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_adaboost)\n",
        "\n",
        "# Mengambil nilai dari confusion matrix\n",
        "TN, FP, FN, TP = conf_matrix.ravel()\n",
        "\n",
        "# Menghitung tipe I dan tipe II error\n",
        "type_i_error = FP\n",
        "type_ii_error = FN\n",
        "# Hitung metric lainnya\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_adaboost)\n",
        "\n",
        "# Cetak hasil\n",
        "print(\"Ada Boost Model Metrics:\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nTrue Positive (TP):\", TP)\n",
        "print(\"True Negative (TN):\", TN)\n",
        "print(\"False Positive (FP):\", FP)\n",
        "print(\"False Negative (FN):\", FN)\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC:\", roc_auc)"
      ],
      "metadata": {
        "id": "S3Mnl76IGx6E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_EYf7pmZjGtA",
        "H4kqzuTfQxSG",
        "IhxI15FdNHpm",
        "spuEYz-xseJo",
        "zYKOErfEV84U",
        "MmYBtDY62uYv",
        "j7Ue7qKS2xUZ",
        "JDc2y1i7lToo",
        "SZIwSYzq4WDm",
        "anZyOXYI7XQy",
        "nbQTv0N2WtJ2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}